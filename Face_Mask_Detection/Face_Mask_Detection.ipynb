{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Mask_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOQensShcCAJuV/yj8HmQBX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c5a0f68222c4da8a270ce827ce6c613": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_be4ab3d359ad431c901edc0535f16395",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_883d6248d97a4990919c6fcd8a1d9f93",
              "IPY_MODEL_e69b702d3297430d91dfaef24ed949db"
            ]
          }
        },
        "be4ab3d359ad431c901edc0535f16395": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "883d6248d97a4990919c6fcd8a1d9f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f0267cb8968849518bf90e1b98a7e4b6",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102530333,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102530333,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8627ecbaa0fe4ba58b223ce11ec9d47f"
          }
        },
        "e69b702d3297430d91dfaef24ed949db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5315a26e2cdc47b3b4f345476e26372e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [4:00:07&lt;00:00, 7.12kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3ad94c9d50841d78f81785a88e0c30a"
          }
        },
        "f0267cb8968849518bf90e1b98a7e4b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8627ecbaa0fe4ba58b223ce11ec9d47f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5315a26e2cdc47b3b4f345476e26372e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3ad94c9d50841d78f81785a88e0c30a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vish109/Machine_Learning/blob/main/Face_Mask_Detection/Face_Mask_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTuAQOraj6Z-",
        "outputId": "88b01440-251d-4631-e093-3d89e46518de"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms \n",
        "import torchvision.models as models\n",
        "from torchsummary import summary\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyJktht8kH2b"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoI8tt_K0tBG"
      },
      "source": [
        "# total images for each label = 2994+108+97+64\n",
        "list_1 = os.listdir('gdrive/MyDrive/Datasets/Face_Mask/Dataset/mask_weared_incorrect_1')\n",
        "list_2 = os.listdir('gdrive/MyDrive/Datasets/Face_Mask/Dataset/with_mask_1')\n",
        "list_3 = os.listdir('gdrive/MyDrive/Datasets/Face_Mask/Dataset/without_mask_1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTGdOv7d6FRu",
        "outputId": "62776b88-9dec-42fe-e749-e8b7effe8c15"
      },
      "source": [
        "img0 = cv2.imread(f'gdrive/MyDrive/Datasets/Face_Mask/Dataset/with_mask_1/{list_2[0]}')\n",
        "print(img0.shape[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWeFaF9vkdx1"
      },
      "source": [
        "\n",
        "class MyData(Dataset):\n",
        "  def __init__(self,file_len,list1,list2,list3,transform):\n",
        "    self.file_len = file_len\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.file_len\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    if(index<2994):\n",
        "      img_path = f'gdrive/MyDrive/Datasets/Face_Mask/Dataset/mask_weared_incorrect/{index+1}.png'\n",
        "      image = cv2.imread(img_path)\n",
        "      y_label = torch.tensor([1, 0, 0])\n",
        "\n",
        "    elif(index>=2994 and index<2994*2):\n",
        "      k = index-2994\n",
        "      img_path = f'gdrive/MyDrive/Datasets/Face_Mask/Dataset/with_mask/{k+1}.png'\n",
        "      image = cv2.imread(img_path)\n",
        "      y_label = torch.tensor([0, 1, 0])\n",
        "    elif(index>=2994*2 and index<2994*3):\n",
        "      k = index-2994*2\n",
        "      img_path = f'gdrive/MyDrive/Datasets/Face_Mask/Dataset/without_mask/{k+1}.png'\n",
        "      image = cv2.imread(img_path)\n",
        "      y_label = torch.tensor([0, 0, 1])\n",
        "    elif(index>=2994*3 and index<(2994*3+108)):\n",
        "      i = 0\n",
        "      img_path = f'gdrive/MyDrive/Datasets/Face_Mask/Dataset/mask_weared_incorrect_1/{list_1[i]}'\n",
        "      image = cv2.imread(img_path)\n",
        "      y_label = torch.tensor([1,0,0])\n",
        "    elif(index>=(2994*3+108) and index<(2994*3+108+97)):\n",
        "      i = 0\n",
        "      img_path = f'gdrive/MyDrive/Datasets/Face_Mask/Dataset/with_mask_1/{list_2[i]}'\n",
        "      image = cv2.imread(img_path)\n",
        "      y_label = torch.tensor([0,1,0])\n",
        "    else:\n",
        "      i = 0\n",
        "      img_path = f'gdrive/MyDrive/Datasets/Face_Mask/Dataset/without_mask_1/{list_3[i]}'\n",
        "      image = cv2.imread(img_path)\n",
        "      y_label = torch.tensor([0,0,1])\n",
        "\n",
        "\n",
        "    if(self.transform):\n",
        "      image = self.transform(image)\n",
        "    \n",
        "    \n",
        "    \n",
        "    return(image,y_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVuQCrqtpbCG"
      },
      "source": [
        "T = transforms.Compose([\n",
        "                        #transforms.ToPILImage(),\n",
        "                        #transforms.ColorJitter(brightness=0.5),\n",
        "                        #transforms.RandomGrayscale(p=0.3),\n",
        "                        transforms.ToTensor(),\n",
        "                        #transforms.Normalize(mean=[0.38434757,0.41674298,0.48780654],std=[2.55361557e-07,1.66943286e-03,1.00000000e-09])\n",
        "                        ])\n",
        "data = MyData(2994*3+108+97+64,list_1,list_2,list_3,transform=T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDBuH4G4pvO1"
      },
      "source": [
        "train_set,val_set = torch.utils.data.random_split(data,[7401,1850])\n",
        "validation_set,test_set = torch.utils.data.random_split(val_set,[925,925])\n",
        "# k = [i for i in train_set if type(i)==None]\n",
        "# print(k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP_l9arxroe_",
        "outputId": "36f575c3-b981-4751-92f0-d52a9b83c3cc"
      },
      "source": [
        "train_load = DataLoader(dataset=train_set,batch_size=16,shuffle=True,drop_last=True)\n",
        "val_load = DataLoader(dataset=validation_set,batch_size=16,shuffle=True,drop_last=True)\n",
        "test_load = DataLoader(dataset=test_set,batch_size=16,shuffle=True,drop_last=True)\n",
        "print(test_load)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7f2db48b8190>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cRXH9YsmM9c"
      },
      "source": [
        "# def get_mean_std(loader):\n",
        "#   channels_sum,channels_squared_sum,num_batches=0,0,0\n",
        "#   for data, _ in loader:\n",
        "#     channels_sum+=torch.mean(data,dim=[0,2,3])\n",
        "#     channels_squared_sum+=torch.mean(data**2,dim=[0,2,3])\n",
        "#     num_batches+=1\n",
        "\n",
        "#   mean = channels_sum/num_batches\n",
        "#   std = (channels_squared_sum/num_batches-mean**2)**0.5\n",
        "\n",
        "#   return [mean,std]\n",
        "# mean_std = get_mean_std(train_load)\n",
        "# print(mean_std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QwCMJaBpdIW"
      },
      "source": [
        "T = transforms.Compose([\n",
        "                        transforms.ToPILImage(),\n",
        "                        transforms.ColorJitter(brightness=0.5),\n",
        "                        transforms.RandomGrayscale(p=0.3),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize(mean=[0.3868, 0.4193, 0.4881],std=[0.2488, 0.2489, 0.2706])\n",
        "                        ])\n",
        "data = MyData(2994*3+108+97+64,list_1,list_2,list_3,transform=T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IxI9-qwppHP",
        "outputId": "89def841-4222-4b7d-9278-b3d54b33602f"
      },
      "source": [
        "train_set,val_set = torch.utils.data.random_split(data,[7401,1850])\n",
        "validation_set,test_set = torch.utils.data.random_split(val_set,[925,925])\n",
        "train_load = DataLoader(dataset=train_set,batch_size=16,shuffle=True,drop_last=True)\n",
        "val_load = DataLoader(dataset=validation_set,batch_size=16,shuffle=True,drop_last=True)\n",
        "test_load = DataLoader(dataset=test_set,batch_size=16,shuffle=True,drop_last=True)\n",
        "print(test_load)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7f2db48b8050>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP9df6ISthDo"
      },
      "source": [
        "# in_channels = 3\n",
        "# num_classes = 3\n",
        "# num_epochs = 5\n",
        "# Model = Net(in_channels=in_channels,num_classes=num_classes)\n",
        "# summary(Model,(3,128,128))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2c5a0f68222c4da8a270ce827ce6c613",
            "be4ab3d359ad431c901edc0535f16395",
            "883d6248d97a4990919c6fcd8a1d9f93",
            "e69b702d3297430d91dfaef24ed949db",
            "f0267cb8968849518bf90e1b98a7e4b6",
            "8627ecbaa0fe4ba58b223ce11ec9d47f",
            "5315a26e2cdc47b3b4f345476e26372e",
            "d3ad94c9d50841d78f81785a88e0c30a"
          ]
        },
        "id": "PY_-tC8u2qx1",
        "outputId": "a22b8baf-5637-4c2f-9f85-1c5f8177ef63"
      },
      "source": [
        "# x = torch.randn(2,3,128,128)\n",
        "# print(Model(x).shape)\n",
        "\n",
        "Model1 = models.resnet50(pretrained=True)\n",
        "# print(summary(Model1,(3,299,299))) \n",
        "print(Model1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c5a0f68222c4da8a270ce827ce6c613",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102530333.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwR--rwQK05u"
      },
      "source": [
        "for params in Model1.parameters():\n",
        "  params.requires_grad = False\n",
        "Model1.fc = nn.Sequential(nn.Linear(in_features=2048,out_features=1000),nn.Dropout(p=0.4,inplace=True),nn.Linear(in_features=1000,out_features=3))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XIBYnEsS6MJ"
      },
      "source": [
        "in_channels = 3\n",
        "num_classes = 3\n",
        "num_epochs = 25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMlk4lBv3Q9L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b81ffc-171c-4c3d-e01c-eb6567952542"
      },
      "source": [
        "cost = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(Model1.parameters(),lr=0.001)\n",
        "lambda1 = lambda epoch: 0.5 ** epoch\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n",
        "\n",
        "\n",
        "\n",
        "#train loop\n",
        "i = 0\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_loss = []\n",
        "  correct = 0\n",
        "  for data in train_load:\n",
        "    x,y = data\n",
        "    scores = Model1(x)\n",
        "    loss = cost(scores,torch.argmax(y,dim=1))\n",
        "    epoch_loss.append(loss)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    correct += (torch.argmax(scores,dim=1) == torch.argmax(y,dim=1)).float().sum()\n",
        "  scheduler.step()\n",
        "  print(f\"epoch: {epoch+1}/{num_epochs} | loss: {sum(epoch_loss)/len(train_set)} | accuracy: {correct/len(train_set)}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 1/25 | loss: 0.039064664393663406 | accuracy: 0.8002972602844238\n",
            "epoch: 2/25 | loss: 0.020155565813183784 | accuracy: 0.8763680458068848\n",
            "epoch: 3/25 | loss: 0.01631009578704834 | accuracy: 0.9046074748039246\n",
            "epoch: 4/25 | loss: 0.014938835054636002 | accuracy: 0.9089311957359314\n",
            "epoch: 5/25 | loss: 0.01362330000847578 | accuracy: 0.9163626432418823\n",
            "epoch: 6/25 | loss: 0.014139777980744839 | accuracy: 0.9160923957824707\n",
            "epoch: 7/25 | loss: 0.013286453671753407 | accuracy: 0.9202810525894165\n",
            "epoch: 8/25 | loss: 0.013763436116278172 | accuracy: 0.9205513000488281\n",
            "epoch: 9/25 | loss: 0.013238433748483658 | accuracy: 0.9244696497917175\n",
            "epoch: 10/25 | loss: 0.013628602959215641 | accuracy: 0.9154168367385864\n",
            "epoch: 11/25 | loss: 0.013898693025112152 | accuracy: 0.917443573474884\n",
            "epoch: 12/25 | loss: 0.013552827760577202 | accuracy: 0.9171733260154724\n",
            "epoch: 13/25 | loss: 0.013555126264691353 | accuracy: 0.9193352460861206\n",
            "epoch: 14/25 | loss: 0.013474014587700367 | accuracy: 0.9183893799781799\n",
            "epoch: 15/25 | loss: 0.012705091387033463 | accuracy: 0.925685703754425\n",
            "epoch: 16/25 | loss: 0.013532492332160473 | accuracy: 0.9183893799781799\n",
            "epoch: 17/25 | loss: 0.014189837500452995 | accuracy: 0.9146061539649963\n",
            "epoch: 18/25 | loss: 0.013450239785015583 | accuracy: 0.9194703698158264\n",
            "epoch: 19/25 | loss: 0.014041587710380554 | accuracy: 0.9140656590461731\n",
            "epoch: 20/25 | loss: 0.013224155642092228 | accuracy: 0.9204161763191223\n",
            "epoch: 21/25 | loss: 0.014306813478469849 | accuracy: 0.9139305353164673\n",
            "epoch: 22/25 | loss: 0.013408740982413292 | accuracy: 0.9178489446640015\n",
            "epoch: 23/25 | loss: 0.012418994680047035 | accuracy: 0.9255505800247192\n",
            "epoch: 24/25 | loss: 0.01317712850868702 | accuracy: 0.9205513000488281\n",
            "epoch: 25/25 | loss: 0.013137041591107845 | accuracy: 0.9205513000488281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqlepGeu9qeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "290be5d4-4844-4f35-b496-69c487bd368f"
      },
      "source": [
        "def check_accuracy(loader,Model1):\n",
        "  correct = 0\n",
        "  samples = 0\n",
        "  Model1.eval()\n",
        "  with torch.no_grad():\n",
        "    for x,y in loader:\n",
        "      scores = Model1(x)\n",
        "      predictions = scores\n",
        "      for i in range(len(y)):\n",
        "        if(torch.argmax(scores[i])==torch.argmax(y[i])):\n",
        "          correct = correct+1\n",
        "        samples = samples+1\n",
        "  print(f'got {float(correct)/float(samples)}')\n",
        "check_accuracy(val_load,Model1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "got 0.9451754385964912\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHEbSIv_NdJ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23643fb4-caf5-421d-b0a6-03e62098a89e"
      },
      "source": [
        "check_accuracy(test_load,Model1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "got 0.9473684210526315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vtHcPDHQAIS"
      },
      "source": [
        "# torch.save(Model1.state_dict(), 'Model.pth.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQjirHDRFd0t"
      },
      "source": [
        "torch.save(Model1,'Entire_Model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}