{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Amz_review_sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMhjOWwwuyAnjNPujLfLTVH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishnunagar109/Machine_Learning/blob/main/Sentiment_Analysis/Amz_review_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0xNtcZAST-M",
        "outputId": "cb3a8a56-f11e-4d86-a240-ad78f8df1442"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjP9Y0TZRZRE"
      },
      "source": [
        "import bz2\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchtext.legacy.data import Field,TabularDataset,BucketIterator\n",
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joXXjta3ReqO"
      },
      "source": [
        "root_dir = 'gdrive/MyDrive/Datasets/torch_text_data/Amazon_sentiment_analysis'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDUSYkYZR98u"
      },
      "source": [
        "# # # #Data preparation in next 4 cells\n",
        "# #This is a one time task, after saving the data into csv files, we only need to load csv files\n",
        "\n",
        "# #1. Saving the data into dictionaries in order to convert them into dataframes later\n",
        "# # # #\n",
        "\n",
        "# train_data = {'text':[],'score':[]}\n",
        "# test_data = {'text':[],'score':[]}\n",
        "# i = 0\n",
        "# with bz2.open(os.path.join(root_dir,'train.ft.txt.bz2'), \"rt\") as bz_file:\n",
        "#     for line in bz_file:\n",
        "#       if(i>=400000):\n",
        "#         break\n",
        "#       i = i+1\n",
        "#       text = line[11:]\n",
        "#       label = int(line[9])\n",
        "#       train_data['text'].append(text)\n",
        "#       train_data['score'].append(label)\n",
        "\n",
        "# i = 0\n",
        "# with bz2.open(os.path.join(root_dir,'test.ft.txt.bz2'), \"rt\") as bz_file:\n",
        "#     for line in bz_file:\n",
        "#       if(i>=10000):\n",
        "#         break\n",
        "#       i = i+1\n",
        "#       text = line[11:]\n",
        "#       label = int(line[9])\n",
        "#       test_data['text'].append(text)\n",
        "#       test_data['score'].append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpkPNleCo7bx"
      },
      "source": [
        "# print(len(train_data['text']))\n",
        "# print(len(test_data['text']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TL9jBriDSMcO"
      },
      "source": [
        "# ####2. Converting the dictionaries into pandas dataframes #####\n",
        "\n",
        "# df_train = pd.DataFrame(train_data,columns=['text','score'])\n",
        "# df_test = pd.DataFrame(test_data,columns=['text','score'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN5q9D8uWbIt"
      },
      "source": [
        "# ####3. Varifying the converted data #####\n",
        "\n",
        "# print(df_train.head())\n",
        "# print(df_test.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZkRz-wBb-Xf"
      },
      "source": [
        "# ####Export the dataframes into csv files #####\n",
        "\n",
        "# df_train.to_csv(os.path.join(root_dir,'train1.csv'),index=False)\n",
        "# df_test.to_csv(os.path.join(root_dir,'test1.csv'),index=False)\n",
        "# df_train.to_json(os.path.join(root_dir,'train1.json'),orient='records',lines=True)\n",
        "# df_test.to_json(os.path.join(root_dir,'test1.json'),orient='records',lines=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhlUxxAignOr"
      },
      "source": [
        "# !zip \"gdrive/MyDrive/Datasets/torch_text_data/Amazon_sentiment_analysis/test.zip\" \"gdrive/MyDrive/Datasets/torch_text_data/Amazon_sentiment_analysis/test.json\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hfobxSgldyf"
      },
      "source": [
        "# train_data = pd.read_csv(os.path.join(root_dir,'train.csv'),index_col=0)\n",
        "# test_data = pd.read_csv(os.path.join(root_dir,'test.csv'),index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAsj0MkcdQ_K"
      },
      "source": [
        "# !python -m spacy download en\n",
        "spacy_eng = spacy.load('en')\n",
        "\n",
        "def tokenizer_eng(text):\n",
        "  return [tok.text for tok in spacy_eng.tokenizer(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORxTzCmaZOsL"
      },
      "source": [
        "text = Field(sequential=True,use_vocab=True,tokenize=tokenizer_eng)\n",
        "score = Field(sequential=False,use_vocab=False)\n",
        "fields = {'text':('t',text),'score':('s',score)}\n",
        "train_data,test_data = TabularDataset.splits(path=root_dir,train='train1.json',test='test1.json',format='json',fields=fields)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysWwm9V7Of6B"
      },
      "source": [
        "text.build_vocab(train_data,max_size=10000,min_freq=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBtWkdokepOH",
        "outputId": "a20f7054-b0ab-4795-f83a-f949fb3b87d8"
      },
      "source": [
        "print(train_data[0].__dict__.keys())\n",
        "print(train_data[0].__dict__.values())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['t', 's'])\n",
            "dict_values([['Stuning', 'even', 'for', 'the', 'non', '-', 'gamer', ':', 'This', 'sound', 'track', 'was', 'beautiful', '!', 'It', 'paints', 'the', 'senery', 'in', 'your', 'mind', 'so', 'well', 'I', 'would', 'recomend', 'it', 'even', 'to', 'people', 'who', 'hate', 'vid', '.', 'game', 'music', '!', 'I', 'have', 'played', 'the', 'game', 'Chrono', 'Cross', 'but', 'out', 'of', 'all', 'of', 'the', 'games', 'I', 'have', 'ever', 'played', 'it', 'has', 'the', 'best', 'music', '!', 'It', 'backs', 'away', 'from', 'crude', 'keyboarding', 'and', 'takes', 'a', 'fresher', 'step', 'with', 'grate', 'guitars', 'and', 'soulful', 'orchestras', '.', 'It', 'would', 'impress', 'anyone', 'who', 'cares', 'to', 'listen', '!', '^_^'], 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckYGkOBhUDep"
      },
      "source": [
        "#Hyperparameters\n",
        "input_size = len(text.vocab)\n",
        "output_size = 1\n",
        "hidden_size = 1024\n",
        "emb_size = 200\n",
        "batch_size = 64\n",
        "num_epochs = 50\n",
        "lr = 0.01\n",
        "num_layers = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpytQNiKu1Nh"
      },
      "source": [
        "#Model\n",
        "class Network(nn.Module):\n",
        "  def __init__(self,input_size,emb_size,hidden_size,output_size,num_layers):\n",
        "    super(Network,self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.num_layers = num_layers\n",
        "    self.embs = nn.Embedding(input_size,emb_size)\n",
        "    self.gru = nn.GRU(emb_size,hidden_size,bidirectional=True)\n",
        "    self.fc = nn.Linear(2*hidden_size,output_size)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self,x,hidden):\n",
        "    x = self.embs(x)\n",
        "    # print(x.size())\n",
        "    # print(x)\n",
        "    # print(x)\n",
        "    out,hidden = self.gru(x,hidden)\n",
        "    # print(out.size())\n",
        "    # out = out.reshape(out.shape[1],-1)\n",
        "    # print(out.size()) \n",
        "    # print(out.size(0))\n",
        "    out = out[int(out.size(0))-1,:,:]\n",
        "    # out1 = out[-1][:][:]\n",
        "    # out2 = out[:][:][-1]\n",
        "    # print(out1.size())\n",
        "    # print(out2.size())\n",
        "    # print(out.size())\n",
        "    out = self.sigmoid(self.fc(out))\n",
        "    # print(out)\n",
        "    # print(out.size())\n",
        "\n",
        "    return out\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return torch.zeros(2*self.num_layers,batch_size,self.hidden_size)\n",
        "\n",
        "Model = Network(input_size,emb_size,hidden_size,output_size,num_layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9E3dN5CXjMU"
      },
      "source": [
        "#Model Hyperparameters\n",
        "pad_idx = text.vocab.stoi['<pad>']\n",
        "criterion = nn.BCELoss()\n",
        "# criterion1 = nn.BCELoss()\n",
        "optimizer = optim.Adam(params=Model.parameters(),lr=lr)\n",
        "lambda1 = lambda epoch: 0.65 ** epoch\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdFicUQ5VVM4"
      },
      "source": [
        "#Getting the batches\n",
        "train_iter,test_iter = BucketIterator.splits((train_data,test_data),batch_size=batch_size,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBAXCAMxWkY4",
        "outputId": "f2ec9f88-2343-449f-ee94-94be925ebe04"
      },
      "source": [
        "#training\n",
        "i = 0\n",
        "for epoch in range(num_epochs):\n",
        "  i = 0\n",
        "  epoch_loss = 0\n",
        "  # hidden = Model.init_hidden()\n",
        "  for idx,batch in enumerate(train_iter):\n",
        "    x = batch.t\n",
        "    y = batch.s\n",
        "    hidden = Model.init_hidden()\n",
        "\n",
        "    # print(x.size())\n",
        "    # print(x.size())\n",
        "    # print(y)\n",
        "    y = torch.tensor([0 if val==1 else 1 for val in y])\n",
        "  #   # print(y.size())\n",
        "    # print(y)\n",
        "    output = Model(x,hidden)\n",
        "  #   # print(y)\n",
        "  #   # print(output.size())\n",
        "  #   # print(torch.argmax(output,1))\n",
        "  #   # output = torch.argmax(output,1)\n",
        "    # print(output.squeeze())\n",
        "  #   # print(y.squeeze())\n",
        "  #   # y = y.squeeze()\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(output.squeeze().float(),y.float())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss+=loss\n",
        "    if(i%100==0):\n",
        "      print(loss)\n",
        "    i+=1\n",
        "\n",
        "  scheduler.step()\n",
        "  print(f\"epoch:{epoch+1}|loss:{float(epoch_loss)/idx}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.6956, grad_fn=<BinaryCrossEntropyBackward>)\n",
            "tensor(0.6951, grad_fn=<BinaryCrossEntropyBackward>)\n",
            "tensor(0.6747, grad_fn=<BinaryCrossEntropyBackward>)\n",
            "tensor(0.6959, grad_fn=<BinaryCrossEntropyBackward>)\n",
            "tensor(0.7641, grad_fn=<BinaryCrossEntropyBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aoFioklYZjY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}